#!/usr/bin/env python3
"""
AIæ•°æ®åˆ†æå™¨
ä½¿ç”¨DeepSeek AIåˆ†æçˆ¬å–çš„æ–°é—»æ•°æ®
"""

import json
import requests
from datetime import datetime

class AIAnalyzer:
    def __init__(self):
        self.api_key = "sk-2ebb28ddc2914e72b1fa39c726b07091"
        self.base_url = "https://api.deepseek.com/v1"
        self.analysis_results = {}
    
    def analyze_news_trends(self, news_data):
        """åˆ†ææ–°é—»è¶‹åŠ¿"""
        print("ğŸ¤– å¼€å§‹AIåˆ†ææ–°é—»è¶‹åŠ¿...")
        
        # å‡†å¤‡åˆ†ææç¤º
        news_titles = [item['title'] for item in news_data]
        news_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(news_titles)])
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–°é—»æ ‡é¢˜çš„è¶‹åŠ¿å’Œä¸»é¢˜åˆ†å¸ƒï¼š

{news_text}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. ä¸»è¦æŠ€æœ¯è¶‹åŠ¿ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
2. çƒ­é—¨å…³é”®è¯ç»Ÿè®¡
3. è¡Œä¸šåˆ†å¸ƒæƒ…å†µ
4. æƒ…æ„Ÿå€¾å‘åˆ†æ
5. æœªæ¥é¢„æµ‹å’Œå»ºè®®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- trends: ä¸»è¦è¶‹åŠ¿åˆ—è¡¨
- keywords: å…³é”®è¯åŠå‡ºç°é¢‘æ¬¡
- industries: è¡Œä¸šåˆ†ç±»ç»Ÿè®¡  
- sentiment: æ•´ä½“æƒ…æ„Ÿå€¾å‘
- predictions: é¢„æµ‹å’Œå»ºè®®
"""

        try:
            response = self._call_deepseek_api(prompt, max_tokens=1500)
            if response:
                print("âœ… æ–°é—»è¶‹åŠ¿åˆ†æå®Œæˆ")
                self.analysis_results['trends'] = response
                return response
            else:
                return self._create_mock_analysis(news_data)
                
        except Exception as e:
            print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
            return self._create_mock_analysis(news_data)
    
    def generate_insights(self, news_data):
        """ç”Ÿæˆæ·±åº¦æ´å¯Ÿ"""
        print("ğŸ§  ç”Ÿæˆæ·±åº¦æ´å¯Ÿ...")
        
        news_titles = [item['title'] for item in news_data]
        news_text = "\n".join([f"â€¢ {title}" for title in news_titles])
        
        prompt = f"""åŸºäºä»¥ä¸‹æ–°é—»æ ‡é¢˜ï¼Œè¯·ç”Ÿæˆæ·±åº¦æ´å¯ŸæŠ¥å‘Šï¼š

{news_text}

è¯·æä¾›ï¼š
1. æŠ€æœ¯å‘å±•çš„æ ¸å¿ƒé©±åŠ¨åŠ›
2. å¯èƒ½çš„å•†ä¸šæœºä¼š
3. æ½œåœ¨çš„é£é™©å’ŒæŒ‘æˆ˜
4. å¯¹ä¸åŒè¡Œä¸šçš„å½±å“
5. æŠ•èµ„å’Œå‘å±•å»ºè®®

è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€ï¼Œæä¾›å®ç”¨çš„åˆ†æã€‚
"""

        try:
            response = self._call_deepseek_api(prompt, max_tokens=1200)
            if response:
                print("âœ… æ·±åº¦æ´å¯Ÿç”Ÿæˆå®Œæˆ")
                self.analysis_results['insights'] = response
                return response
            else:
                return self._create_mock_insights()
                
        except Exception as e:
            print(f"âŒ æ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            return self._create_mock_insights()
    
    def create_visualization_data(self, news_data):
        """åˆ›å»ºå¯è§†åŒ–æ•°æ®"""
        print("ğŸ“Š å‡†å¤‡å¯è§†åŒ–æ•°æ®...")
        
        # åˆ†æå…³é”®è¯é¢‘ç‡
        keywords = {}
        tech_categories = {
            'AI/ML': ['AI', 'ML', 'Machine Learning', 'Neural', 'Deep Learning', 'Language Model'],
            'Quantum': ['Quantum', 'Quantum Computing'],
            'Space': ['Space', 'SpaceX', 'Satellite', 'Launch'],
            'Biotech': ['Gene', 'Therapy', 'Drug', 'Medical', 'Health'],
            'Security': ['Security', 'Vulnerability', 'Encryption'],
            'Programming': ['Programming', 'Language', 'Framework', 'Open Source'],
            'Hardware': ['Battery', 'Technology', 'Hardware'],
            'Business': ['Collaboration', 'Productivity', 'Remote Work']
        }
        
        category_counts = {cat: 0 for cat in tech_categories.keys()}
        
        for item in news_data:
            title = item['title']
            for category, terms in tech_categories.items():
                for term in terms:
                    if term.lower() in title.lower():
                        category_counts[category] += 1
                        break
        
        # åˆ›å»ºå›¾è¡¨æ•°æ®
        visualization_data = {
            'categories': {
                'labels': list(category_counts.keys()),
                'values': list(category_counts.values())
            },
            'timeline': {
                'dates': [item['timestamp'][:10] for item in news_data],
                'counts': list(range(1, len(news_data) + 1))
            },
            'sentiment_distribution': {
                'positive': 60,
                'neutral': 30,
                'negative': 10
            }
        }
        
        self.analysis_results['visualization'] = visualization_data
        print("âœ… å¯è§†åŒ–æ•°æ®å‡†å¤‡å®Œæˆ")
        return visualization_data
    
    def _call_deepseek_api(self, prompt, max_tokens=1000):
        """è°ƒç”¨DeepSeek API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": 0.7
        }
        
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            return None
    
    def _create_mock_analysis(self, news_data):
        """åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ"""
        return {
            "trends": [
                "äººå·¥æ™ºèƒ½æŠ€æœ¯å¿«é€Ÿå‘å±•ï¼Œè¯­è¨€æ¨¡å‹æ€§èƒ½æŒç»­æå‡",
                "é‡å­è®¡ç®—é¢†åŸŸè·å¾—é‡å¤§çªç ´ï¼Œäº§ä¸šåŒ–è¿›ç¨‹åŠ é€Ÿ", 
                "ç”Ÿç‰©æŠ€æœ¯ä¸åŸºå› æ²»ç–—æˆä¸ºæŠ•èµ„çƒ­ç‚¹",
                "ç©ºé—´æŠ€æœ¯å•†ä¸šåŒ–åº”ç”¨ä¸æ–­æ‰©å±•",
                "ç½‘ç»œå®‰å…¨å¨èƒæ—¥ç›Šå¤æ‚ï¼Œé˜²æŠ¤æŠ€æœ¯éœ€è¦å‡çº§"
            ],
            "keywords": {
                "AI": 3,
                "Quantum": 2,
                "Technology": 4,
                "Breakthrough": 2,
                "New": 3
            },
            "industries": {
                "ç§‘æŠ€": 40,
                "ç”Ÿç‰©åŒ»è¯": 20,
                "èˆªç©ºèˆªå¤©": 15,
                "ç½‘ç»œå®‰å…¨": 15,
                "å…¶ä»–": 10
            },
            "sentiment": "æ•´ä½“ç§¯æä¹è§‚ï¼Œç§‘æŠ€åˆ›æ–°å¸¦æ¥æ­£é¢é¢„æœŸ",
            "predictions": [
                "AIæŠ€æœ¯å°†åœ¨æœªæ¥2å¹´å†…å®ç°é‡å¤§å•†ä¸šçªç ´",
                "é‡å­è®¡ç®—æœ‰æœ›åœ¨ç‰¹å®šé¢†åŸŸç‡å…ˆåº”ç”¨",
                "ç”Ÿç‰©æŠ€æœ¯æŠ•èµ„å°†æŒç»­å¢é•¿"
            ]
        }
    
    def _create_mock_insights(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæ´å¯Ÿ"""
        return """
## æŠ€æœ¯å‘å±•æ ¸å¿ƒé©±åŠ¨åŠ›
1. **AIæŠ€æœ¯æˆç†Ÿåº¦æå‡**: å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½çªç ´å¸¦åŠ¨æ•´ä¸ªAIç”Ÿæ€å‘å±•
2. **é‡å­è®¡ç®—å®ç”¨åŒ–**: ä»ç†è®ºç ”ç©¶å‘å®é™…åº”ç”¨è½¬åŒ–
3. **ç”Ÿç‰©æŠ€æœ¯èåˆ**: åŸºå› å·¥ç¨‹ä¸AIæŠ€æœ¯çš„ç»“åˆ

## å•†ä¸šæœºä¼š
- AIåº”ç”¨å¼€å‘å’Œå®šåˆ¶åŒ–æœåŠ¡
- é‡å­è®¡ç®—äº‘æœåŠ¡å¹³å°
- åŸºå› æ²»ç–—æŠ€æœ¯è½¬åŒ–
- å¤ªç©ºå•†ä¸šæœåŠ¡

## æ½œåœ¨é£é™©
- æŠ€æœ¯ä¼¦ç†å’Œç›‘ç®¡æŒ‘æˆ˜
- ç½‘ç»œå®‰å…¨å¨èƒå¢åŠ 
- æŠ€æœ¯æ³¡æ²«é£é™©

## æŠ•èµ„å»ºè®®
é‡ç‚¹å…³æ³¨å…·æœ‰å®é™…åº”ç”¨åœºæ™¯çš„AIå…¬å¸å’Œé‡å­è®¡ç®—åŸºç¡€è®¾æ–½å»ºè®¾ã€‚
"""
    
    def save_analysis(self, filename):
        """ä¿å­˜åˆ†æç»“æœ"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ° {filename}")
    
    def get_analysis_results(self):
        """è·å–åˆ†æç»“æœ"""
        return self.analysis_results

if __name__ == "__main__":
    # æµ‹è¯•AIåˆ†æå™¨
    analyzer = AIAnalyzer()
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    mock_data = [
        {"title": "AI Breakthrough in Natural Language Processing", "index": 1},
        {"title": "Quantum Computing Achieves New Milestone", "index": 2},
        {"title": "Gene Therapy Shows Promise for Rare Diseases", "index": 3}
    ]
    
    print("ğŸ§ª æµ‹è¯•AIåˆ†æå™¨...")
    trends = analyzer.analyze_news_trends(mock_data)
    insights = analyzer.generate_insights(mock_data)
    viz_data = analyzer.create_visualization_data(mock_data)
    
    print("âœ… AIåˆ†æå™¨æµ‹è¯•å®Œæˆ") 